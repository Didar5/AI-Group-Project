{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    df_maj = train_df[df.click == 0]\n",
    "    df_min = train_df[df.click == 1]\n",
    "\n",
    "    # Negative downsampling rate\n",
    "    w = 0.025\n",
    "\n",
    "    # Majority class sampled without replacement\n",
    "    df_maj = sklearn.utils.resample(df_maj, replace = False, \n",
    "                                                     n_samples = int(w * df_maj.shape[0]))\n",
    "\n",
    "    # Combine the downsampled majority class and the minority class and shuffle\n",
    "    df_downsample = pd.concat([df_maj, df_min]).sample(frac = 1)\n",
    "    \n",
    "    return df_downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to put slot prices into pre-defined buckets\n",
    "\n",
    "def buckets(x):\n",
    "\n",
    "    if x >= 0 and x < 1:\n",
    "        return 'first_bucket'\n",
    "    elif x >= 1 and x <= 10:\n",
    "        return 'second_bucket'\n",
    "    elif x >= 11 and x <= 50:\n",
    "        return 'third_bucket'\n",
    "    elif x >= 51 and x <= 100:\n",
    "        return 'fourth_bucet'\n",
    "    else:\n",
    "        return 'fifth_bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to preprocess data\n",
    "def features(df):\n",
    "    # The test set does not have bid- or payprise\n",
    "    if 'bidprice' and 'payprice' in df.columns:\n",
    "        df['bidprice'] = df['bidprice'].apply(lambda x: x/1000.0)\n",
    "        df['payprice'] = df['payprice'].apply(lambda x: x/1000.0)\n",
    "    \n",
    "    df['slotprice_buckets'] = df['slotprice'].apply(buckets)\n",
    "    df['slotprice'] = df['slotprice'].apply(lambda x: x/1000.0)\n",
    "    df['os'] = df['useragent'].apply(lambda x: x.split('_')[0])\n",
    "    df['browser'] = df['useragent'].apply(lambda x: x.split('_')[1])\n",
    "    df['weekday'] = df['weekday'].apply(lambda x: str(x))\n",
    "    df['hour'] = df['hour'].apply(lambda x: str(x))\n",
    "    df['region'] = df['region'].apply(lambda x: str(x))\n",
    "    df['city'] = df['city'].apply(lambda x: str(x))\n",
    "    df['adexchange'] = df['adexchange'].apply(lambda x: str(x))\n",
    "    df['advertiser'] = df['advertiser'].apply(lambda x: str(x))\n",
    "    df['slot_width*height'] = df['slotwidth'].apply(lambda x: str(x)) + '*' \\\n",
    "                            + df['slotheight'].apply(lambda x: str(x))\n",
    "    \n",
    "    if 'bidprice' and 'payprice' in df.columns:\n",
    "        drop = ['bidid', 'bidprice', 'userid', 'url', 'urlid', 'IP', 'slotid', 'slotwidth', 'slotheight',\n",
    "                'useragent']\n",
    "    else:\n",
    "        drop = ['bidid', 'bidprice', 'userid', 'url', 'urlid', 'IP', 'slotid', 'slotwidth', 'slotheight',\n",
    "                'useragent']\n",
    "    df = df.drop(drop, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(df):\n",
    "    df['usertag'] = df['usertag'].apply(lambda x: str(x).split(','))\n",
    "    \n",
    "    AllTags = np.array(df['usertag'])\n",
    "    Tags = [tag for usertags in AllTags for tag in usertags]\n",
    "    Tags = list(set(Tags))\n",
    "    \n",
    "    for t in Tags:\n",
    "        df['usertag_' + t] = df['usertag'].apply(lambda x: int(t in x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to extract the summary statistics\n",
    "\n",
    "def stats(df):\n",
    "    # Create DataFrames including statistics\n",
    "    df_stats = df[['click', 'bidprice', 'payprice', 'advertiser']].sum()\n",
    "    \n",
    "    # Impressions\n",
    "    df_stats['impressions'] = df.shape[0]\n",
    "    \n",
    "    # CTR, CPM, and eCPC\n",
    "    df_stats['CTR'] = df_stats['click']/df_stats['impressions']\n",
    "    df_stats['CPM'] = (df_stats['payprice']/df_stats['impressions'])*1000.0\n",
    "    df_stats['eCPC'] = df_stats['payprice']/df_stats['click']\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Create a new downsampled training DataFrame, used for the Logistic Regression\n",
    "new_train_df = downsample(train_df)\n",
    "\n",
    "# Easier to work with the usertag feature seperately\n",
    "q = DataFrame(new_train_df['usertag'])\n",
    "\n",
    "new_train_df = new_train_df.drop('usertag', axis = 1)\n",
    "new_train_df = features(new_train_df)\n",
    "\n",
    "q = tag(q)\n",
    "q = q.drop('usertag', axis = 1)\n",
    "\n",
    "cols = ['payprice', 'slotprice']\n",
    "p = DataFrame(new_train_df[cols])\n",
    "new_train_df = new_train_df.drop(cols, axis = 1)\n",
    "\n",
    "new_train_df = pd.get_dummies(new_train_df)\n",
    "new_train_df = pd.concat([new_train_df, q, p], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "validation_df = pd.read_csv('validation.csv')\n",
    "\n",
    "q = DataFrame(validation_df['usertag'])\n",
    "\n",
    "validation_df = validation_df.drop('usertag', axis = 1)\n",
    "validation_df = features(validation_df)\n",
    "\n",
    "q = tag(q)\n",
    "q = q.drop('usertag', axis = 1)\n",
    "\n",
    "cols = ['payprice', 'slotprice']\n",
    "p = DataFrame(validation_df[cols])\n",
    "validation_df = validation_df.drop(cols, axis = 1)\n",
    "\n",
    "validation_df = pd.get_dummies(validation_df)\n",
    "validation_df = pd.concat([validation_df, q, p], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat = new_train_df.columns\n",
    "validation_feat = validation_df.columns\n",
    "feat = [x for x in validation_feat if x in train_feat]\n",
    "\n",
    "new_train_df = new_train_df[feat]\n",
    "validation_df = validation_df[feat]\n",
    "\n",
    "len(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = new_train_df.click\n",
    "X_train = new_train_df.drop(['click', 'payprice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62522, 4227)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = validation_df.click\n",
    "X_val = validation_df.drop(['click', 'payprice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thorbjornthorarinsson/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'C': array([0.01, 0.12, 0.23, 0.34, 0.45, 0.56, 0.67, 0.78, 0.89, 1.  ]), 'penalty': ['l2'], 'class_weight': ['balanced']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'C': np.linspace(start=0.01,stop=1,num=10),\"penalty\":[\"l2\"], \"class_weight\":[\"balanced\"]}]\n",
    "model = GridSearchCV(LogisticRegression(max_iter=500),param_grid=tuned_parameters,scoring=\"roc_auc\",cv=5,n_jobs=-1 )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No click</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No click</th>\n",
       "      <td>253765</td>\n",
       "      <td>49958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Click</th>\n",
       "      <td>58</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          No click  Click\n",
       "No click    253765  49958\n",
       "Click           58    144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedgrid = model.predict(X_val)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = DataFrame(metrics.confusion_matrix(y_val, predictedgrid), \n",
    "                     columns = ['No click', 'Click'], \n",
    "                     index = ['No click', 'Click'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Logistic Regression AU ROC: ', metrics.roc_auc_score(y_val,  model.predict_proba(X_val)[:,1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AU ROC:  0.83710557916846\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 500, solver = 'lbfgs', class_weight = 'balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_val)\n",
    "\n",
    "print ('Logistic Regression AU ROC: ', metrics.roc_auc_score(y_val,  model.predict_proba(X_val)[:,1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pCTR, important to remember to re-calibrate because we trained on downsampled data\n",
    "predicted_CTR = model.predict_proba(X_val)[:,1]\n",
    "predicted_CTR = predicted_CTR/(predicted_CTR+((1-predicted_CTR)/0.025)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for the base_bid search\n",
    "budget = 6250\n",
    "best_basebid = 0\n",
    "best_clicks = 0\n",
    "avg_ctr = train_df.click.value_counts()[1] / (train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(spent.shape[0]):\n",
    "        if i == (spent.shape[0] - 1):\n",
    "            index = i\n",
    "            break\n",
    "            \n",
    "        elif spent.iloc[i] > budget:\n",
    "            index = i - 1\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search to find the base_bid that yields the highest number of clicks\n",
    "for base_bid in np.linspace(validation_df['payprice'].min(), validation_df['payprice'].max(), 1000):\n",
    "    # The formula for the linear proble, defined in the paper\n",
    "    validation_df['bid'] = base_bid * (predicted_CTR/avg_ctr)\n",
    "    \n",
    "    # Payprice, bid and clicks for the instances we have the winning bid\n",
    "    impressions = validation_df[(validation_df['bid'] >= validation_df['slotprice']) \\\n",
    "                                & (validation_df['bid'] >= validation_df['payprice'])] \\\n",
    "                                [['payprice', 'bid', 'click']]\n",
    "    \n",
    "    spent = impressions['payprice'].cumsum()\n",
    "    spent = DataFrame(spent)\n",
    "    index = len(spent[spent['payprice'] < budget])\n",
    "    \n",
    "    # Number of clicks\n",
    "    clicks = impressions['click'].loc[:index].sum()\n",
    "    \n",
    "    if clicks > best_clicks:\n",
    "        best_basebid = base_bid \n",
    "        best_clicks = clicks\n",
    "\n",
    "print(best_basebid)\n",
    "best_bid = best_basebid * (predicted_CTR/avg_ctr) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "q = DataFrame(test_df['usertag'])\n",
    "\n",
    "test_df = test_df.drop('usertag', axis = 1)\n",
    "test_df = features(test_df)\n",
    "\n",
    "q = tag(q)\n",
    "q = q.drop('usertag', axis = 1)\n",
    "\n",
    "test_df = pd.get_dummies(test_df)\n",
    "test_df = pd.concat([test_df, q], axis = 1)\n",
    "\n",
    "new_train_df = new_train_df[feat].drop(['payprice', 'bidprice'], axis = 1)\n",
    "test_df = test_df[feat]\n",
    "\n",
    "predicted = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['click', 'bidid', 'payprice', 'bidprice'], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
